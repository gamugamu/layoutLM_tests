{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ccb819-2cec-452c-90dc-f23c40663dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorflow-hub in /usr/local/lib/python3.11/dist-packages (0.16.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (4.9.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-hub --no-deps\n",
    "!pip install tensorflow-datasets --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862e38b0-e6b1-4150-a2e5-c767135a8922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.14.0\n",
      "Eager mode:  True\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 11:53:37.092601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-20 11:53:37.126280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-20 11:53:37.126320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "#print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49773b8d-e263-4751-80c6-c0a443c06d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set into 60% and 40% to end up with 15,000 examples\n",
    "# for training, 10,000 examples for validation and 25,000 examples for testing.\n",
    "train_data, validation_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "763bcc0f-e478-4f09-aecb-b673939416fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:03:20.516401: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 50), dtype=float32, numpy=\n",
       "array([[ 0.5423195 , -0.0119017 ,  0.06337538,  0.06862972, -0.16776837,\n",
       "        -0.10581174,  0.16865303, -0.04998824, -0.31148055,  0.07910346,\n",
       "         0.15442263,  0.01488662,  0.03930153,  0.19772711, -0.12215476,\n",
       "        -0.04120981, -0.2704109 , -0.21922152,  0.26517662, -0.80739075,\n",
       "         0.25833532, -0.3100421 ,  0.28683215,  0.1943387 , -0.29036492,\n",
       "         0.03862849, -0.7844411 , -0.0479324 ,  0.4110299 , -0.36388892,\n",
       "        -0.58034706,  0.30269456,  0.3630897 , -0.15227164, -0.44391504,\n",
       "         0.19462997,  0.19528408,  0.05666234,  0.2890704 , -0.28468323,\n",
       "        -0.00531206,  0.0571938 , -0.3201318 , -0.04418665, -0.08550783,\n",
       "        -0.55847436, -0.23336391, -0.20782952, -0.03543064, -0.17533456],\n",
       "       [ 0.56338924, -0.12339553, -0.10862679,  0.7753425 , -0.07667089,\n",
       "        -0.15752277,  0.01872335, -0.08169781, -0.3521876 ,  0.4637341 ,\n",
       "        -0.08492756,  0.07166859, -0.00670817,  0.12686075, -0.19326553,\n",
       "        -0.52626437, -0.3295823 ,  0.14394785,  0.09043556, -0.5417555 ,\n",
       "         0.02468163, -0.15456742,  0.68333143,  0.09068331, -0.45327246,\n",
       "         0.23180096, -0.8615696 ,  0.34480393,  0.12838456, -0.58759046,\n",
       "        -0.4071231 ,  0.23061076,  0.48426893, -0.27128142, -0.5380916 ,\n",
       "         0.47016326,  0.22572741, -0.00830663,  0.2846242 , -0.304985  ,\n",
       "         0.04400365,  0.25025874,  0.14867121,  0.40717036, -0.15422426,\n",
       "        -0.06878027, -0.40825695, -0.3149215 ,  0.09283665, -0.20183425],\n",
       "       [ 0.7456154 ,  0.21256861,  0.14400336,  0.5233862 ,  0.11032254,\n",
       "         0.00902788, -0.3667802 , -0.08938274, -0.24165542,  0.33384594,\n",
       "        -0.11194605, -0.01460047, -0.0071645 ,  0.19562712,  0.00685216,\n",
       "        -0.24886718, -0.42796347,  0.18620004, -0.05241098, -0.66462487,\n",
       "         0.13449019, -0.22205497,  0.08633006,  0.43685386,  0.2972681 ,\n",
       "         0.36140734, -0.7196889 ,  0.05291241, -0.14316116, -0.1573394 ,\n",
       "        -0.15056328, -0.05988009, -0.08178931, -0.15569411, -0.09303783,\n",
       "        -0.18971172,  0.07620788, -0.02541647, -0.27134508, -0.3392682 ,\n",
       "        -0.10296468, -0.27275252, -0.34078008,  0.20083304, -0.26644835,\n",
       "         0.00655449, -0.05141488, -0.04261917, -0.45413622,  0.20023568]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
    "\n",
    "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "hub_layer(train_examples_batch[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbeaeacb-1b2e-42d6-af85-9258a83e02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_keras as ktf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa76b47-1cef-4eae-a928-cb3bedef94dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ktf.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(ktf.layers.Dense(16, activation='relu'))\n",
    "model.add(ktf.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62544470-7909-4055-aaeb-4b88465b04d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 50)                48190600  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                816       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48191433 (183.84 MB)\n",
      "Trainable params: 48191433 (183.84 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7af986a-2a8e-4676-bfc4-c8c3f66b7d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ffcb51-bee4-4f24-a379-7d4444ac763c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 25s 454ms/step - loss: 0.6608 - accuracy: 0.5412 - val_loss: 0.5998 - val_accuracy: 0.6205\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 13s 445ms/step - loss: 0.5264 - accuracy: 0.7065 - val_loss: 0.4840 - val_accuracy: 0.7593\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 13s 442ms/step - loss: 0.3906 - accuracy: 0.8280 - val_loss: 0.3942 - val_accuracy: 0.8297\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 13s 442ms/step - loss: 0.2841 - accuracy: 0.8917 - val_loss: 0.3428 - val_accuracy: 0.8541\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 13s 449ms/step - loss: 0.2108 - accuracy: 0.9253 - val_loss: 0.3196 - val_accuracy: 0.8663\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 13s 443ms/step - loss: 0.1570 - accuracy: 0.9513 - val_loss: 0.3067 - val_accuracy: 0.8651\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 13s 445ms/step - loss: 0.1162 - accuracy: 0.9665 - val_loss: 0.3036 - val_accuracy: 0.8703\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 13s 445ms/step - loss: 0.0853 - accuracy: 0.9787 - val_loss: 0.3084 - val_accuracy: 0.8698\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 13s 441ms/step - loss: 0.0624 - accuracy: 0.9883 - val_loss: 0.3145 - val_accuracy: 0.8743\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 13s 437ms/step - loss: 0.0457 - accuracy: 0.9933 - val_loss: 0.3252 - val_accuracy: 0.8728\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = ktf.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(train_data.shuffle(10000).batch(512),\n",
    "           epochs=10,\n",
    "            validation_data=validation_data.batch(512),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bde41550-b783-44c8-b28e-a0281e2037c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf_keras.src.callbacks.History object at 0x7fd62825d350> logs/fit/20240618-184959\n",
      "0 0.6607714295387268 0.5998238325119019\n",
      "1 0.5264492034912109 0.48396065831184387\n",
      "2 0.39057764410972595 0.3942417502403259\n",
      "3 0.28414714336395264 0.34279686212539673\n",
      "4 0.21081192791461945 0.3195594549179077\n",
      "5 0.1569909155368805 0.3066900670528412\n",
      "6 0.11622925847768784 0.30360376834869385\n",
      "7 0.08534103631973267 0.3083646297454834\n",
      "8 0.06241045147180557 0.3144962787628174\n",
      "9 0.045731306076049805 0.325151264667511\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "print(history, log_dir)\n",
    "writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "with writer.as_default():\n",
    "    for epoch, (train_loss, val_loss, acc, val_acc) in enumerate(zip(history.history['loss'], history.history['val_loss'], history.history['accuracy'], history.history['val_accuracy'])):\n",
    "        print(epoch, train_loss, val_loss)\n",
    "        tf.summary.scalar('loss', train_loss, step=epoch)\n",
    "        tf.summary.scalar('val_loss', val_loss, step=epoch)\n",
    "        tf.summary.scalar('accuracy', acc, step=epoch)\n",
    "        tf.summary.scalar('val_acc', val_acc, step=epoch)\n",
    "\n",
    "        writer.flush()\n",
    "        # Ajouter d'autres métriques si nécessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14d27e00-fd09-4462-99b0-1cdf8450eed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6607714295387268,\n",
       "  0.5264492034912109,\n",
       "  0.39057764410972595,\n",
       "  0.28414714336395264,\n",
       "  0.21081192791461945,\n",
       "  0.1569909155368805,\n",
       "  0.11622925847768784,\n",
       "  0.08534103631973267,\n",
       "  0.06241045147180557,\n",
       "  0.045731306076049805],\n",
       " 'accuracy': [0.5411999821662903,\n",
       "  0.7065333127975464,\n",
       "  0.828000009059906,\n",
       "  0.8916666507720947,\n",
       "  0.925266683101654,\n",
       "  0.9513333439826965,\n",
       "  0.9664666652679443,\n",
       "  0.9787333607673645,\n",
       "  0.98826664686203,\n",
       "  0.9933333396911621],\n",
       " 'val_loss': [0.5998238325119019,\n",
       "  0.48396065831184387,\n",
       "  0.3942417502403259,\n",
       "  0.34279686212539673,\n",
       "  0.3195594549179077,\n",
       "  0.3066900670528412,\n",
       "  0.30360376834869385,\n",
       "  0.3083646297454834,\n",
       "  0.3144962787628174,\n",
       "  0.325151264667511],\n",
       " 'val_accuracy': [0.6205000281333923,\n",
       "  0.7592999935150146,\n",
       "  0.8296999931335449,\n",
       "  0.8540999889373779,\n",
       "  0.8662999868392944,\n",
       "  0.8651000261306763,\n",
       "  0.8702999949455261,\n",
       "  0.8697999715805054,\n",
       "  0.8743000030517578,\n",
       "  0.8727999925613403]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff533e-f304-4efe-b8e0-af0968964107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
